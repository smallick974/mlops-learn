{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset, Experiment\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#Metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import make_scorer, accuracy_score ,precision_score,recall_score,f1_score\n",
        "\n",
        "#Model Select\n",
        "from sklearn.model_selection import KFold,train_test_split,cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1731330130423
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Access the registered dataset\n",
        "processed_data = Dataset.get_by_name(workspace=ws, name='iris_data_set')\n",
        "\n",
        "# Load the dataset into a pandas DataFrame\n",
        "df = processed_data.to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe'}\n{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe', 'activityApp': 'TabularDataset'}\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731330136834
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create or get an existing experiment \n",
        "experiment = Experiment(workspace=ws, name='model-training')\n",
        "\n",
        "# Start a new run \n",
        "run = experiment.start_logging()"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731330140458
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.iloc[:,0:4].values\n",
        "y=df.iloc[:,4].values"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731330142428
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731330144418
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train and Test split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731330184726
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "random_forest = RandomForestClassifier(n_estimators=100)\n",
        "random_forest.fit(X_train, y_train)\n",
        "Y_prediction = random_forest.predict(X_test)\n",
        "accuracy_rf=round(accuracy_score(y_test,Y_prediction)* 100, 2)\n",
        "acc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, Y_prediction)\n",
        "accuracy = accuracy_score(y_test,Y_prediction)\n",
        "precision =precision_score(y_test, Y_prediction,average='micro')\n",
        "recall =  recall_score(y_test, Y_prediction,average='micro')\n",
        "f1 = f1_score(y_test,Y_prediction,average='micro')\n",
        "\n",
        "\n",
        "# Convert confusion matrix to a DataFrame for better readability \n",
        "conf_matrix_df = pd.DataFrame(cm) \n",
        "# Convert DataFrame to a dictionary \n",
        "conf_matrix_dict = conf_matrix_df.to_dict()\n",
        "\n",
        "run.log('Confusion matrix for Random Forest', conf_matrix_dict)\n",
        "\n",
        "formatted_accuracy = format(accuracy, '.3f')\n",
        "run.log('accuracy_random_forest', formatted_accuracy)\n",
        "\n",
        "formatted_precision = format(precision, '.3f')\n",
        "run.log('precision_random_Forest', formatted_precision)\n",
        "\n",
        "formatted_recall = format(recall, '.3f')\n",
        "run.log('recall_random_Forest', formatted_recall)\n",
        "\n",
        "formatted_f1 = format(f1, '.3f')\n",
        "run.log('f1-score_random_Forest', formatted_f1)\n",
        "\n",
        "print('Confusion matrix for Random Forest\\n',cm)\n",
        "print('accuracy_random_Forest : %.3f' %accuracy)\n",
        "print('precision_random_Forest : %.3f' %precision)\n",
        "print('recall_random_Forest : %.3f' %recall)\n",
        "print('f1-score_random_Forest : %.3f' %f1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Confusion matrix for Random Forest\n [[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [1 6 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0]\n [0 0 0 0 0 0 0 5 2 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]]\naccuracy_random_Forest : 0.244\nprecision_random_Forest : 0.244\nrecall_random_Forest : 0.244\nf1-score_random_Forest : 0.244\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731330923019
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression(solver= 'saga',max_iter=500)\n",
        "logreg.fit(X_train, y_train)\n",
        "Y_pred = logreg.predict(X_test)\n",
        "accuracy_lr=round(accuracy_score(y_test,Y_pred)* 100, 2)\n",
        "acc_log = round(logreg.score(X_train, y_train) * 100, 2)\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, Y_pred,)\n",
        "accuracy = accuracy_score(y_test,Y_pred)\n",
        "precision =precision_score(y_test, Y_pred,average='micro')\n",
        "recall =  recall_score(y_test, Y_pred,average='micro')\n",
        "f1 = f1_score(y_test,Y_pred,average='micro')\n",
        "print('Confusion matrix for Logistic Regression\\n',cm)\n",
        "print('accuracy_Logistic Regression : %.3f' %accuracy)\n",
        "print('precision_Logistic Regression : %.3f' %precision)\n",
        "print('recall_Logistic Regression: %.3f' %recall)\n",
        "print('f1-score_Logistic Regression : %.3f' %f1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Confusion matrix for Logistic Regression\n [[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0]\n [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 1 0 0]\n [0 3 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 3 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]]\naccuracy_Logistic Regression : 0.244\nprecision_Logistic Regression : 0.244\nrecall_Logistic Regression: 0.244\nf1-score_Logistic Regression : 0.244\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731331266206
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run.complete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}